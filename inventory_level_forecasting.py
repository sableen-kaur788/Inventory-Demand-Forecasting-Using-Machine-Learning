# -*- coding: utf-8 -*-
"""Inventory Level Forecasting

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cZzUw0dLRD67kfcZfRI5JbjLPcxCZ3QL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/sales_data.csv')

df.head()

df.shape

df.info()

df.columns

"""#Data Preprocessing"""

df = df.drop(columns=['Store ID', 'Product ID'])

df['Date']=pd.to_datetime(df['Date'])
df['Year']=df['Date'].dt.year
df['Month']=df['Date'].dt.month

# List of columns to convert
cat_cols = ['Region', 'Category', 'Seasonality', 'Year', 'Month', 'Weather Condition', 'Epidemic', 'Promotion']
df[cat_cols] = df[cat_cols].astype('category')

cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
num_cols = df.select_dtypes(include=['int32', 'int64', 'float64', 'datetime64']).columns.tolist()
print("Categorical Columns:", cat_cols)
print("Numerical Columns:",num_cols)

df.isnull().sum().any()

df.isnull().sum()

num_duplicates = df.duplicated().sum()
print(f"Number of duplicate rows: {num_duplicates}")

df = df.drop_duplicates()
print(df.shape)

df.describe()

fig, axes = plt.subplots(1, 2, figsize=(12, 5))
# Histogram
axes[0].hist(df['Inventory Level'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Inventory Level', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Inventory Level', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Inventory Level'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Inventory Level', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Inventory Level', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Inventory Level'])

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(12, 5))
# Histogram
axes[0].hist(df['Units Sold'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Units Sold', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Units Solds', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Units Sold'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Unit Solds', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Unit Solds', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Units Sold'])

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(11, 5))
# Histogram
axes[0].hist(df['Units Ordered'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Units Ordered', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Units Ordered', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Units Ordered'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Unit Ordered', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Unit Ordered', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Units Ordered'])

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(11, 5))
# Histogram
axes[0].hist(df['Price'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Price', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Units Ordered', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Price'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Unit Ordered', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Unit Ordered', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Units Ordered'])

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(12, 5))
# Histogram
axes[0].hist(df['Demand'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Demand', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Demand', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Demand'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Demand', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Demand', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Demand'])

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(11, 5))
# Histogram
axes[0].hist(df['Competitor Pricing'], bins=20, edgecolor='pink')
axes[0].set_xlabel('Competitor Pricing', color='darkred', fontsize=14)
axes[0].set_ylabel('Frequency', color='darkred', fontsize=14)
axes[0].set_title('Distribution of Competitor Pricing', color='darkred', fontweight='bold', fontsize=16)
axes[0].grid(axis='y', linestyle='--', alpha=0.7)
# Boxplot
axes[1].boxplot(
    df['Competitor Pricing'],
    patch_artist=True,
    boxprops=dict(facecolor='green', color='yellow', alpha=0.8),
    medianprops=dict(color='red', linewidth=1),
    whiskerprops=dict(color='darkred'),
    flierprops=dict(marker='o', markersize=5, color='black', markerfacecolor='red')
)
axes[1].set_xlabel('Competitor Pricing', color='darkred', fontsize=14)
axes[1].set_title('Boxplot of Competitor Pricing', color='darkred', fontweight='bold', fontsize=16)
axes[1].set_xticks([1])
axes[1].set_xticklabels(['Competitor Pricing'])

plt.tight_layout()
plt.show()

"""#Outlier Detection"""

# To Detect outliers
cols = ['Inventory Level', 'Units Sold', 'Units Ordered']
for col in cols:
  Q1 = df[col].quantile(0.25)
  Q3 = df[col].quantile(0.75)
  IQR = Q3 - Q1

  lower_bound = Q1 - 1.5*IQR
  upper_bound = Q3 + 1.5*IQR

  outliers = df[(df[col]<lower_bound) | (df[col]>upper_bound)]
  print(f"{col} : Outliers Found = {outliers.shape[0]}")

df_cleaned = df.copy()
cols = ['Inventory Level', 'Units Sold', 'Units Ordered']
for col in cols:
  Q1 = df_cleaned[col].quantile(0.25)
  Q3 = df_cleaned[col].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR
  df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]

print("Original shape:", df.shape)
print("Cleaned shape:", df_cleaned.shape)

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
numerical_cols

"""#Visualization"""

# Monthly Demand Trend by Year (Line Plot)
import calendar
monthly_demand = df.groupby(["Year", "Month"], observed=False)["Demand"].mean().reset_index()
pivot_df = monthly_demand.pivot(index="Month", columns="Year", values="Demand")

pivot_df.plot(figsize=(10,5), marker="o")
plt.title("Monthly Demand Trend by Year", fontsize=16, fontweight='bold')
plt.xlabel("Month", fontsize=14)
plt.ylabel("Average Demand", fontsize=14)
plt.xticks(ticks=range(1,13), labels=[calendar.month_abbr[m] for m in range(1,13)])
plt.grid(True)
plt.show()

print(monthly_demand)
print(pivot_df)

# Demand Distribution - Histogram
plt.figure(figsize=(8,5))
plt.hist(df["Demand"], bins=20, color="skyblue", edgecolor="black", alpha=0.7)
plt.title("Demand Distribution (Histogram)")
plt.xlabel("Demand")
plt.ylabel("Frequency")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Effect of Promotions
promo_demand = df.groupby("Promotion", observed=False)["Demand"].mean().reset_index()
plt.figure(figsize=(7,6))
plt.bar(promo_demand["Promotion"].astype(str), promo_demand["Demand"], color=["skyblue","orange"])
plt.title("Effect of Promotions on Demand", fontweight='bold', fontsize=16)
plt.xlabel("Promotion (0=No, 1=Yes)", fontsize=14)
plt.ylabel("Average Demand", fontsize=14)
plt.show()

# Effect of Weather
plt.figure(figsize=(9, 6))
weather_demand = df.groupby("Weather Condition", observed=False)["Demand"].mean().reset_index()
colors=plt.cm.viridis(np.linspace(0,1,len(weather_demand)))
plt.bar(weather_demand["Weather Condition"], weather_demand["Demand"], color=colors)
plt.title("Effect of Weather on Demand", fontweight='bold', fontsize=16)
plt.xlabel("Weather Condition", fontsize=14)
plt.ylabel("Average Demand", fontsize=14)
plt.xticks(ha="right")
plt.show()

"""#Heatmap"""

plt.figure(figsize=(8, 6))
corr = df[numerical_cols].corr()
heat = plt.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)
plt.colorbar(heat)
plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')
plt.yticks(range(len(corr.columns)), corr.columns)
plt.title('Correlation Matrix', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

for col in ['Category', 'Region', 'Weather Condition', 'Promotion', 'Seasonality', 'Epidemic']:
  unique_values = df_cleaned[col].unique()
  print(f'Column:{col}')
  print(f'Unique values ({len(unique_values)}) : {unique_values}')

"""#Data Preparation"""

df_cleaned.shape

df_cleaned = df_cleaned.drop(columns=['Date', 'Month', 'Year'])

X = df_cleaned.drop(columns=['Demand'])
y = df_cleaned['Demand']

"""#Encoding"""

from sklearn.preprocessing import OneHotEncoder
cat_cols = X.select_dtypes(include=['object', 'category']).columns

# One-hot encoding
X = pd.get_dummies(X, columns=cat_cols, drop_first=True)

# Save the column names of X after get_dummies
import joblib
joblib.dump(list(X.columns), 'columns.pkl')

"""#Data Splitting"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""#Data Scaling"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

"""#1. Linear Model"""

model_linear = make_pipeline(
    MinMaxScaler(),
    LinearRegression()
)
model_linear.fit(X_train, y_train)

# Prediction
y_train_pred = model_linear.predict(X_train)
y_test_pred  = model_linear.predict(X_test)

# Evaluate the model on Training set
train_mse = mean_squared_error(y_train, y_train_pred)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2  = r2_score(y_train, y_train_pred)

# Evaluate the model on Testing set
test_mse = mean_squared_error(y_test, y_test_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2_linear = r2_score(y_test, y_test_pred)

# Print results
print("Training Performance:")
print("MSE:", train_mse)
print("MAE:", train_mae)
print("R²:", train_r2)

print("\nTesting Performance:")
print("MSE:", test_mse)
print("MAE:", test_mae)
print("R²:", test_r2_linear)

y_train_pred = model_linear.predict(X_train)
y_test_pred  = model_linear.predict(X_test)

def plot_model(y_true, y_pred, model_name="Linear Regression"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot performance on Test Data
plot_model(y_test, y_test_pred, model_name="Linear Regression")

"""#2. Polynomial Model"""

from sklearn.pipeline import make_pipeline
model_poly = make_pipeline(
    MinMaxScaler(),
    PolynomialFeatures(degree=3, include_bias=False),
    Ridge(alpha=1.0)
)
# Fit model on training data (raw features, not pre-scaled)
model_poly.fit(X_train, y_train)
# Predictions
y_train_pred = model_poly.predict(X_train)
y_test_pred  = model_poly.predict(X_test)

# Metrics
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

test_mse = mean_squared_error(y_test, y_test_pred)
test_rmse = np.sqrt(test_mse)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2_poly  = r2_score(y_test, y_test_pred)

# Print Results
print("Training Performance:")
print("MSE:", train_mse)
print("RMSE:", train_rmse)
print("MAE:", train_mae)
print("R²:", train_r2)

print("\nTesting Performance:")
print("MSE:", test_mse)
print("RMSE:", test_rmse)
print("MAE:", test_mae)
print("R²:", test_r2_poly)

y_train_pred = model_poly.predict(X_train)
y_test_pred  = model_poly.predict(X_test)

def plot_model(y_true, y_pred, model_name="Polynomial Regression"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot performance on Test Data
plot_model(y_test, y_test_pred, model_name="Polynomial Regression")

"""#3. KNN Model"""

# KNN model
model_knn = make_pipeline(
    MinMaxScaler(),
    KNeighborsRegressor(
        n_neighbors=5,
        weights='distance',
        p=1
    )
)
# Fit model
model_knn.fit(X_train, y_train)
# Predictions
y_train_pred = model_knn.predict(X_train)
y_test_pred  = model_knn.predict(X_test)

# Training performance
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = np.sqrt(train_mse)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2  = r2_score(y_train, y_train_pred)

# Testing performance
test_mse = mean_squared_error(y_test, y_test_pred)
test_rmse = np.sqrt(test_mse)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2_knn  = r2_score(y_test, y_test_pred)

# Print results
print("Training Performance:")
print("MSE:", train_mse)
print("RMSE:", train_rmse)
print("MAE:", train_mae)
print("R²:", train_r2)

print("\nTesting Performance:")
print("MSE:", test_mse)
print("RMSE:", test_rmse)
print("MAE:", test_mae)
print("R²:", test_r2_knn)

# Predictions from KNN
y_train_pred = model_knn.predict(X_train)
y_test_pred  = model_knn.predict(X_test)

# Function to plot model performance
def plot_model(y_true, y_pred, model_name="KNN"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot on Test Data
plot_model(y_test, y_test_pred, model_name="KNN")

"""#4. Decision Tree"""

model_dt = DecisionTreeRegressor( max_depth=5,
    min_samples_leaf=10,
    random_state=42)

model_dt.fit(X_train, y_train)
# Predictions
y_train_pred_dt = model_dt.predict(X_train)
y_test_pred_dt  = model_dt.predict(X_test)

# Training performance
train_mse_dt = mean_squared_error(y_train, y_train_pred_dt)
train_rmse_dt = np.sqrt(train_mse_dt)
train_mae_dt = mean_absolute_error(y_train, y_train_pred_dt)
train_r2_dt  = r2_score(y_train, y_train_pred_dt)

# Testing performance
test_mse_dt = mean_squared_error(y_test, y_test_pred_dt)
test_rmse_dt = np.sqrt(test_mse_dt)
test_mae_dt = mean_absolute_error(y_test, y_test_pred_dt)
test_r2_dt  = r2_score(y_test, y_test_pred_dt)

print("Training Performance:")
print("MSE:", train_mse_dt)
print("RMSE:", train_rmse_dt)
print("MAE:", train_mae_dt)
print("R²:", train_r2_dt)

print("\nTesting Performance :")
print("MSE:", test_mse_dt)
print("RMSE:", test_rmse_dt)
print("MAE:", test_mae_dt)
print("R²:", test_r2_dt)

# Predictions from Decision Forest
y_train_pred = model_dt.predict(X_train)
y_test_pred = model_dt.predict(X_test)

# Function to plot model performance
def plot_model(y_true, y_pred, model_name="Decision Tree"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot on Test Data
plot_model(y_test, y_test_pred, model_name="Decision Tree")

"""#5. Random Forest"""

model_rf = RandomForestRegressor(
    n_estimators=200,
    max_depth=10,   # limit depth to avoid small noisy splits
    min_samples_split=5, # minimum samples to split
    min_samples_leaf=3, # minimum samples per leaf
    max_features='sqrt', # consider sqrt(n_features) at each split
    random_state=42,
)
model_rf.fit(X_train, y_train)
# Predictions
y_train_pred_rf = model_rf.predict(X_train)
y_test_pred_rf  = model_rf.predict(X_test)

# Training performance
train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)
train_rmse_rf = np.sqrt(train_mse_rf)
train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)
train_r2_rf  = r2_score(y_train, y_train_pred_rf)

# Testing performance
test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)
test_rmse_rf = np.sqrt(test_mse_rf)
test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)
test_r2_rf  = r2_score(y_test, y_test_pred_rf)

print("\nTraining Performance:")
print("MSE:", train_mse_rf)
print("RMSE:", train_rmse_rf)
print("MAE:", train_mae_rf)
print("R²:", train_r2_rf)

print("\nTesting Performance:")
print("MSE:", test_mse_rf)
print("RMSE:", test_rmse_rf)
print("MAE:", test_mae_rf)
print("R²:", test_r2_rf)

# Save the column names of X after get_dummies
import joblib

# X = pd.get_dummies(X, columns=cat_cols, drop_first=True) # This line is not needed
joblib.dump(list(X.columns), 'columns.pkl')

joblib.dump(model_rf, 'random_model.pkl')

# Predictions from Random Forest
y_train_pred = model_rf.predict(X_train)
y_test_pred = model_rf.predict(X_test)

# Function to plot model performance
def plot_model(y_true, y_pred, model_name="Random Forest"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot on Test Data
plot_model(y_test, y_test_pred, model_name="Random Forest")

"""#6. Support Vector Regressor"""

# Initialize SVR model
model_svr = make_pipeline(
    StandardScaler(),
    SVR(kernel='rbf', C=1.0, epsilon=0.1)
)
model_svr.fit(X_train, y_train)
# Predictions
y_train_pred_svr = model_svr.predict(X_train)
y_test_pred_svr  = model_svr.predict(X_test)

# Training performance
train_mse_svr = mean_squared_error(y_train, y_train_pred_svr)
train_rmse_svr = np.sqrt(train_mse_svr)
train_mae_svr = mean_absolute_error(y_train, y_train_pred_svr)
train_r2_svr  = r2_score(y_train, y_train_pred_svr)

# Testing performance
test_mse_svr = mean_squared_error(y_test, y_test_pred_svr)
test_rmse_svr = np.sqrt(test_mse_svr)
test_mae_svr = mean_absolute_error(y_test, y_test_pred_svr)
test_r2_svr  = r2_score(y_test, y_test_pred_svr)

print("\nTraining Performance (SVR):")
print("MSE:", train_mse_svr)
print("RMSE:", train_rmse_svr)
print("MAE:", train_mae_svr)
print("R²:", train_r2_svr)

print("\nTesting Performance (SVR):")
print("MSE:", test_mse_svr)
print("RMSE:", test_rmse_svr)
print("MAE:", test_mae_svr)
print("R²:", test_r2_svr)

y_train_pred_svr = model_svr.predict(X_train)
y_test_pred_svr  = model_svr.predict(X_test)

# Function to plot model performance
def plot_model(y_true, y_pred, model_name="SVR"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

# Plot performance on Test Data
plot_model(y_test, y_test_pred_svr, model_name="SVR")

# Model names
models = ['Linear Regression', 'Polynomial', 'KNN', 'Decision Tree', 'Random Forest', 'SVR']
r2_scores = [test_r2_linear, test_r2_poly, test_r2_knn, test_r2_dt, test_r2_rf,test_r2_svr]

plt.figure(figsize=(12, 6))
colors = plt.cm.viridis(np.linspace(0, 1, len(models)))
bars = plt.bar(models, r2_scores, color=colors, linewidth=1.2)

plt.ylim(0, 1)
plt.title("Test Set R² Scores for Different Models", fontsize=14, fontweight='bold')
plt.xlabel("Models", fontsize=14, fontweight='bold')
plt.ylabel("R² Score", fontsize=14, fontweight='bold')

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.02, f"{height:.2f}",
             ha='center', va='bottom', fontsize=10, fontweight='bold')

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

def plot_model(y_true, y_pred, model_name="Model"):
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. Predicted vs Actual
    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolor="k")
    axes[0].plot([y_true.min(), y_true.max()],
                 [y_true.min(), y_true.max()], "r--", lw=2)
    axes[0].set_title(f"{model_name}: Predicted vs Actual")
    axes[0].set_xlabel("Actual Demand")
    axes[0].set_ylabel("Predicted Demand")

    # 2. Residuals vs Predicted
    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolor="k")
    axes[1].axhline(0, color="r", linestyle="--", lw=2)
    axes[1].set_title(f"{model_name}: Residuals vs Predicted")
    axes[1].set_xlabel("Predicted Demand")
    axes[1].set_ylabel("Residuals")

    # 3. Residual Distribution
    sns.histplot(residuals, bins=30, kde=True, ax=axes[2])
    axes[2].set_title(f"{model_name}: Residual Distribution")
    axes[2].set_xlabel("Residuals")

    plt.tight_layout()
    plt.show()

def preprocess_input(user_input, X_columns):
    df = pd.DataFrame([user_input])
    df_encoded = pd.get_dummies(df)
    # Reindex to match training columns
    df_encoded = df_encoded.reindex(columns=X_columns, fill_value=0)
    return df_encoded

user_input = {
    "Category": input("Category (Electronics/Clothing/Groceries/Toys/Furniture): "),
    "Region": input("Region (North/South/East/West): "),
    "Inventory Level": float(input("Inventory Level: ")),
    "Units Sold": float(input("Units Sold: ")),
    "Units Ordered": float(input("Units Ordered: ")),
    "Price": float(input("Price: ")),
    "Discount": float(input("Discount %: ")),
    "Weather Condition": input("Weather Condition (Snowy/Cloudy/Sunny/Rainy): "),
    "Promotion": int(input("Promotion (0=No, 1=Yes): ")),
    "Competitor Pricing": float(input("Competitor Pricing: ")),
    "Seasonality": input("Seasonality (Winter/Spring/Summer/Autumn): "),
    "Epidemic": int(input("Epidemic (0=No, 1=Yes): "))
}

X_new = preprocess_input(user_input, X.columns)  # X.columns from your training data

pred_linear = model_linear.predict(X_new)[0]
pred_knn    = model_knn.predict(X_new)[0]
pred_poly   = model_poly.predict(X_new)[0]  # pipeline handles scaling
pred_dt     = model_dt.predict(X_new)[0]
pred_rf     = model_rf.predict(X_new)[0]
pred_svr    = model_svr.predict(X_new)[0]


print("\nPredictions for New Entry:")
print(f"Linear Regression: Predicted Demand = {pred_linear:.2f}")
print(f"Polynomial Ridge:  Predicted Demand = {pred_poly:.2f}")
print(f"KNN:               Predicted Demand = {pred_knn:.2f}")
print(f"Decision Tree:     Predicted Demand = {pred_dt:.2f}")
print(f"Random Forest:     Predicted Demand = {pred_rf:.2f}")
print(f"SVR:               Predicted Demand = {pred_svr:.2f}")

df_cleaned.tail(100)

import joblib

# Save the polynomial model
joblib.dump(model_poly, 'polynomial_model.pkl')